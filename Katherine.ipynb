{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Convolutional Neural Networks\n",
    "\n",
    "### Katherine Wirskye, Lucas Li, Ethan Li, and Kaylie Nguyen (5000-level students)\n",
    "\n",
    "Link to dataset: **insert this shi**\n",
    "\n",
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "# import tensorflow as tf\n",
    "#import pandas as pd\n",
    "# from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.models import Model\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "# from PIL import Image\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomTranslation, RandomZoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 35685\n",
      "Number of labels: 35685\n"
     ]
    }
   ],
   "source": [
    "# locate directories\n",
    "folder = \"allimages\"\n",
    "\n",
    "image_directories = [\n",
    "    os.path.join(folder, \"angry\"),\n",
    "    os.path.join(folder, \"disgust\"),\n",
    "    os.path.join(folder, \"fear\"),\n",
    "    os.path.join(folder, \"happy\"),\n",
    "    os.path.join(folder, \"neutral\"),\n",
    "    os.path.join(folder, \"sad\"),\n",
    "    os.path.join(folder, \"surprise\")\n",
    "]\n",
    "\n",
    "# function to get image paths and the emotion label\n",
    "def get_image_paths_and_labels(image_directories):\n",
    "    image_paths = [] #stores image paths\n",
    "    labels = [] #stores labels\n",
    "\n",
    "    # goes through each of the 7 directories \n",
    "    for i, directory in enumerate(image_directories):\n",
    "        emotion_label = os.path.basename(directory) # captures the emotion label\n",
    "        # goes through each image in each directory\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_paths.append(os.path.join(directory, filename)) #appends image path to list\n",
    "                labels.append(emotion_label) # appends emotion label to list\n",
    "\n",
    "    return image_paths, labels\n",
    "\n",
    "# gets image path and label for training and testing set\n",
    "image_paths, image_labels = get_image_paths_and_labels(image_directories)\n",
    "\n",
    "print(\"Number of images:\", len(image_paths))\n",
    "print(\"Number of labels:\", len(image_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35685 35685\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_images(image_paths, img_width, img_height):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = load_img(img_path, target_size=(img_width, img_height))\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "img_width = 48\n",
    "img_height = 48\n",
    "\n",
    "X = load_and_preprocess_images(image_paths, img_width, img_height)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels for training data\n",
    "labels_encoded = label_encoder.fit_transform(image_labels)\n",
    "\n",
    "# Convert the encoded labels to one-hot encoded vectors\n",
    "y = to_categorical(labels_encoded)\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metric\n",
    "\n",
    "**discuss choice here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting Method\n",
    "\n",
    "**discuss choice here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the 5-fold stratified cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# we can probably changes this to 10 later (10 is probably better for statistical test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### Data Expansion\n",
    "\n",
    "I think we're just gonna add the layers actually in the models. I've added some layers for the first one. So we can just talk about the data expansion here :D\n",
    "\n",
    "So far, we have:\n",
    "- random horizontal flip\n",
    "- random rotation\n",
    "- random translation\n",
    "- random zoom\n",
    "\n",
    "*Setup the training to use data expansion in Keras (also called data augmentation). \n",
    "Explain why the chosen data expansion techniques are appropriate for your dataset. \n",
    "You should make use of Keras augmentation layers, like in the class examples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "\n",
    "Kaylie pls add description of how this model works thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "714/714 [==============================] - 36s 49ms/step - loss: 1.6338 - accuracy: 0.3069 - val_loss: 5.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "714/714 [==============================] - 36s 50ms/step - loss: 1.5722 - accuracy: 0.3384 - val_loss: 6.1622 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "714/714 [==============================] - 37s 52ms/step - loss: 1.5230 - accuracy: 0.3693 - val_loss: 6.8706 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "714/714 [==============================] - 38s 53ms/step - loss: 1.4793 - accuracy: 0.3976 - val_loss: 7.2092 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "714/714 [==============================] - 37s 52ms/step - loss: 1.4345 - accuracy: 0.4218 - val_loss: 8.8884 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "714/714 [==============================] - 37s 52ms/step - loss: 1.3941 - accuracy: 0.4408 - val_loss: 7.3921 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "714/714 [==============================] - 38s 54ms/step - loss: 1.3527 - accuracy: 0.4592 - val_loss: 10.1963 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "714/714 [==============================] - 38s 53ms/step - loss: 1.3297 - accuracy: 0.4771 - val_loss: 12.4049 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "714/714 [==============================] - 40s 56ms/step - loss: 1.3173 - accuracy: 0.4824 - val_loss: 14.5543 - val_accuracy: 0.0366\n",
      "Epoch 10/20\n",
      "714/714 [==============================] - 39s 55ms/step - loss: 1.2944 - accuracy: 0.4966 - val_loss: 14.8303 - val_accuracy: 7.0053e-04\n",
      "Epoch 11/20\n",
      "714/714 [==============================] - 40s 56ms/step - loss: 1.2799 - accuracy: 0.5014 - val_loss: 16.4372 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "714/714 [==============================] - 39s 55ms/step - loss: 1.2623 - accuracy: 0.5087 - val_loss: 16.6098 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "714/714 [==============================] - 40s 56ms/step - loss: 1.2589 - accuracy: 0.5120 - val_loss: 21.3072 - val_accuracy: 5.2539e-04\n",
      "Epoch 14/20\n",
      "714/714 [==============================] - 40s 56ms/step - loss: 1.2437 - accuracy: 0.5204 - val_loss: 22.0024 - val_accuracy: 7.0053e-04\n",
      "Epoch 15/20\n",
      "714/714 [==============================] - 41s 58ms/step - loss: 1.2382 - accuracy: 0.5231 - val_loss: 28.0916 - val_accuracy: 0.0011\n",
      "Epoch 16/20\n",
      "714/714 [==============================] - 41s 58ms/step - loss: 1.2342 - accuracy: 0.5216 - val_loss: 33.9503 - val_accuracy: 0.0011\n",
      "Epoch 17/20\n",
      "714/714 [==============================] - 48s 67ms/step - loss: 1.2210 - accuracy: 0.5297 - val_loss: 27.3942 - val_accuracy: 0.0012\n",
      "Epoch 18/20\n",
      "714/714 [==============================] - 42s 59ms/step - loss: 1.2131 - accuracy: 0.5359 - val_loss: 25.7896 - val_accuracy: 5.2539e-04\n",
      "Epoch 19/20\n",
      "714/714 [==============================] - 44s 62ms/step - loss: 1.2032 - accuracy: 0.5386 - val_loss: 29.5410 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "714/714 [==============================] - 43s 60ms/step - loss: 1.1982 - accuracy: 0.5414 - val_loss: 26.0362 - val_accuracy: 0.0000e+00\n",
      "224/224 [==============================] - 4s 18ms/step - loss: 6.1745 - accuracy: 0.4381\n",
      "Test Loss:  6.174479007720947\n",
      "Test Accuracy: 0.43813925981521606\n"
     ]
    }
   ],
   "source": [
    "# for tracking performance\n",
    "training_results_model1_1 = []\n",
    "testing_results_model1_1 = []\n",
    "\n",
    "# Using stratified k-fold, we call it like this:\n",
    "for train_index, test_index in skf.split(X, labels_encoded):\n",
    "    \n",
    "    # Split the image arrays\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    # Use one-hot encoded labels for the model\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Kaylie's code yay!\n",
    "    # build a model\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "    model1_1 = Sequential([\n",
    "\n",
    "        # data expansion and augmentation (should be talked abt previously)\n",
    "        # these might be decreasing accuracy (I don't know if they're contradicting the pre processing Kaylie did)\n",
    "        # need to discuss this ^^\n",
    "        RandomFlip(\"horizontal\"),\n",
    "        RandomRotation(0.10),\n",
    "        RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        RandomZoom(height_factor=0.1, width_factor=0.1),\n",
    "\n",
    "        # Kaylie's model architecture\n",
    "        # can she write a summary of this?\n",
    "        Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid', activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid', activation='relu'),\n",
    "        Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "        Flatten(),\n",
    "        Dense(1024, activation = 'relu'),\n",
    "        Dense(512, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.25),\n",
    "        Dense(7, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # I dont think we converge; this should be increased\n",
    "    epochs = 20\n",
    "    batch_size = 32\n",
    "\n",
    "    model1_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # traing the model\n",
    "    history = model1_1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "    # add verbose = 0 later!!\n",
    "\n",
    "    # track accuracy and loss for training data and validation data\n",
    "    training_results_model1_1.append({\n",
    "        'loss': history.history['loss'],\n",
    "        'accuracy': history.history['accuracy'],\n",
    "        'val_loss': history.history['val_loss'],\n",
    "        'val_accuracy': history.history['val_accuracy']\n",
    "    })\n",
    "\n",
    "    # evaluate the model on the test data\n",
    "    test_loss, test_accuracy = model1_1.evaluate(X_test, y_test)\n",
    "    # add verbose = 0 later!!\n",
    "\n",
    "    # remove the print statements later\n",
    "    # we won't want them when we run 10 times\n",
    "    print('Test Loss: ', test_loss)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    testing_results_model1_1.append(test_accuracy)\n",
    "\n",
    "    # breaking for now so that we don't waste time running it a billion times (actually only five times LOLLLLL)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss Across Training Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of epochs from one of the training histories\n",
    "num_epochs = len(training_results_model1_1[0]['loss'])\n",
    "\n",
    "# Initialize lists to store the average loss and validation loss across all instances\n",
    "avg_loss1 = []\n",
    "avg_val_loss1 = []\n",
    "\n",
    "# Calculate the average loss and validation loss for each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = [result['loss'][epoch] for result in training_results_model1_1]\n",
    "    epoch_val_loss = [result['val_loss'][epoch] for result in training_results_model1_1]\n",
    "    \n",
    "    avg_loss1.append(np.mean(epoch_loss))\n",
    "    avg_val_loss1.append(np.mean(epoch_val_loss))\n",
    "\n",
    "# Plot the average training and validation loss across all instances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_loss1, label='Average Training Loss')\n",
    "plt.plot(avg_val_loss1, label='Average Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Average Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performance Across Training Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the average accuracy and validation accuracy across all instances\n",
    "avg_accuracy1 = []\n",
    "avg_val_accuracy1 = []\n",
    "\n",
    "# Calculate the average accuracy and validation accuracy for each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_accuracy = [result['accuracy'][epoch] for result in training_results_model1_1]\n",
    "    epoch_val_accuracy = [result['val_accuracy'][epoch] for result in training_results_model1_1]\n",
    "    \n",
    "    avg_accuracy1.append(np.mean(epoch_accuracy))\n",
    "    avg_val_accuracy1.append(np.mean(epoch_val_accuracy))\n",
    "\n",
    "# Plot the average training and validation accuracy across all instances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_accuracy1, label='Average Training Accuracy')\n",
    "plt.plot(avg_val_accuracy1, label='Average Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Average Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average tseting accuracy\n",
    "average1 = np.mean(testing_results_model1_1)\n",
    "std1 = np.std(testing_results_model1_1)\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(testing_results_model1_1)), testing_results_model1_1, color='skyblue', edgecolor='black', label='Values')\n",
    "\n",
    "# Plot the average as a horizontal line\n",
    "plt.axhline(average1, color='red', linestyle='--', linewidth=2, label=f'Average ({average1:.4f})')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Fold Number', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Testing Accuracy Across Folds', fontsize=14)\n",
    "plt.xticks(range(len(testing_results_model1_1)))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print average and standard deviation for accuracy\n",
    "print(\"Average Accuracy: \", average1)\n",
    "print(\"Standard Deviation: \" , std1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 with Changed Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 with Changed Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
